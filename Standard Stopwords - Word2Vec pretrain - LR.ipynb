{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f277522c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>an amazing joystick. I especially love that yo...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Definitely a silent mouse... Not a single clic...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One Star poor quality work and not as it is ad...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good, but could be bettee nice, but tend to sl...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great but flawed. Great amiibo, great for coll...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  star_rating\n",
       "0  an amazing joystick. I especially love that yo...            5\n",
       "1  Definitely a silent mouse... Not a single clic...            5\n",
       "2  One Star poor quality work and not as it is ad...            1\n",
       "3  good, but could be bettee nice, but tend to sl...            3\n",
       "4  Great but flawed. Great amiibo, great for coll...            4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the Amazon reviews dataset\n",
    "data_en = pd.read_pickle(r\"C:\\Users\\phreb\\Data\\data_en.pickle\")\n",
    "\n",
    "# Combine the review headline and body into a single text column\n",
    "data_en[\"Review\"] = data_en[\"review_headline\"] + \" \" + data_en[\"review_body\"]\n",
    "\n",
    "# Define the input and output data\n",
    "data_clean = data_en[[\"Review\",\"star_rating\"]]\n",
    "data_clean[\"Review\"] = data_clean[\"Review\"].fillna(\"\")\n",
    "\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39375183",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_us' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m CountVectorizer(stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Converting the text to numeric data\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m X_cv \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX_us\u001b[49m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Creating a sparse dataframe\u001b[39;00m\n\u001b[0;32m     14\u001b[0m CountVectorizedData \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_cv, columns\u001b[38;5;241m=\u001b[39mvectorizer\u001b[38;5;241m.\u001b[39mget_feature_names())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_us' is not defined"
     ]
    }
   ],
   "source": [
    "X = data_clean[\"Review\"]\n",
    "y = data_clean[\"star_rating\"]\n",
    "\n",
    "# Count vectorization of text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Creating the vectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Converting the text to numeric data\n",
    "X_cv = vectorizer.fit_transform(X_us)\n",
    "\n",
    "# Creating a sparse dataframe\n",
    "CountVectorizedData = pd.DataFrame(X_cv, columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Adding the target variable\n",
    "CountVectorizedData['star_rating'] = y_us\n",
    "\n",
    "print(CountVectorizedData.shape)\n",
    "CountVectorizedData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd29eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X_us, y_us, test_size= 0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val, random_state=42)\n",
    "\n",
    "print(X_us.shape)\n",
    "print(y_us.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04a8fa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count vectorization of text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    " \n",
    "# Ticket Data\n",
    "corpus = TicketData['body'].values\n",
    " \n",
    "# Creating the vectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    " \n",
    "# Converting the text to numeric data\n",
    "X = vectorizer.fit_transform(corpus)\n",
    " \n",
    "#print(vectorizer.get_feature_names())\n",
    " \n",
    "# Preparing Data frame For machine learning\n",
    "# Priority column acts as a target variable and other columns as predictors\n",
    "CountVectorizedData=pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "CountVectorizedData['Priority']=TicketData['urgency']\n",
    "print(CountVectorizedData.shape)\n",
    "CountVectorizedData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba6fc77",
   "metadata": {},
   "source": [
    "### Perform POS tagging on the tokenized reviews\n",
    "> X_train_pos = [pos_tag(tokens) for tokens in X_train_tokens]\n",
    "\n",
    "> X_test_pos = [pos_tag(tokens) for tokens in X_test_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b99166a",
   "metadata": {},
   "source": [
    "### Word2Vec and Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "177663f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "GoogleModel = gensim.models.KeyedVectors.load_word2vec_format(r\"C:/Users/phreb/data/GoogleNews-vectors-negative300.bin\", binary=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03363921",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 28\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(W2Vec_Data)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Since there are so many words... This will take some time :( \u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Calling the function to convert all the text data to Word2Vec Vectors\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m X_train_w2v\u001b[38;5;241m=\u001b[39m\u001b[43mFunctionText2Vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m X_test_w2v\u001b[38;5;241m=\u001b[39mFunctionText2Vec(X_test)\n",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m, in \u001b[0;36mFunctionText2Vec\u001b[1;34m(inpTextData)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mFunctionText2Vec\u001b[39m(inpTextData):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Converting the text to numeric data\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(inpTextData)\n\u001b[0;32m      4\u001b[0m     CountVecData\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(X\u001b[38;5;241m.\u001b[39mtoarray(), columns\u001b[38;5;241m=\u001b[39mvectorizer\u001b[38;5;241m.\u001b[39mget_feature_names())\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Creating empty dataframe to hold sentences\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "def FunctionText2Vec(inpTextData):\n",
    "    # Converting the text to numeric data\n",
    "    X = vectorizer.transform(inpTextData)\n",
    "    CountVecData=pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "    \n",
    "    # Creating empty dataframe to hold sentences\n",
    "    W2Vec_Data=pd.DataFrame()\n",
    "    \n",
    "    # Looping through each row for the data\n",
    "    for i in range(CountVecData.shape[0]):\n",
    " \n",
    "        # initiating a sentence with all zeros\n",
    "        Sentence = np.zeros(300)\n",
    " \n",
    "        # Looping thru each word in the sentence and if its present in \n",
    "        # the Word2Vec model then storing its vector\n",
    "        for word in WordsVocab[CountVecData.iloc[i , :]>=1]:\n",
    "            #print(word)\n",
    "            if word in GoogleModel.key_to_index.keys():    \n",
    "                Sentence=Sentence+GoogleModel[word]\n",
    "        # Appending the sentence to the dataframe\n",
    "        W2Vec_Data=W2Vec_Data.append(pd.DataFrame([Sentence]))\n",
    "    return(W2Vec_Data)\n",
    "\n",
    "\n",
    "# Since there are so many words... This will take some time :( \n",
    "# Calling the function to convert all the text data to Word2Vec Vectors\n",
    "X_train_w2v=FunctionText2Vec(X_train)\n",
    "X_test_w2v=FunctionText2Vec(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02dd4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression model\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_features, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = lr_model.predict(X_test_features)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
