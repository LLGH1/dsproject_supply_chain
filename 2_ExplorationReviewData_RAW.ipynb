{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Supply Chain -- Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible Questions for the Project:\n",
    "\n",
    "Are customers happier with digital products than with physical ones?\n",
    "\n",
    "Are customers willing to switch to digital products from physical ones when they had a positive/negative experience\n",
    "\n",
    "**Exploration of metadata (without Text Mining technics)**\n",
    "Some ideas (from Maelys):\n",
    "\n",
    "- Response rate, influence of brand or source, verified_purchase or not\n",
    "\n",
    "- Distribution of scores.\n",
    "\n",
    "- Influence of the marketplace or the company on the distribution of notes (hypothesis testin could be used for  this kind of analysis )\n",
    "\n",
    "- Information about the 10 most active users, with a small analysis on it (distribution of scores, response rate, company...).\n",
    "\n",
    "**Goal 2 Analysis of text (and cleaning if necessary ). You will need to complete the text mining module to be able to do this part.**\n",
    "Some ideas :\n",
    "- Analyze the punctuation according to the note\n",
    "\n",
    "- Analyze the length of the text (nb character, nb words...) according to the note.\n",
    "\n",
    "- Analyze the frequency of email addresses, links, phone numbers...\n",
    "\n",
    "- Occurrence of words, wordcloud...\n",
    "\n",
    "- N-gram\n",
    "\n",
    "- Occurrence of some words : delivery order, return order, delivery, SAV, customer service..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm # color map\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "project_path = os.path.abspath(os.path.join(os.getcwd(), os.path.pardir, os.path.pardir)).replace('\\\\', '/')\n",
    "project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hc = pd.read_csv(project_path + '/data/amazon_reviews_us_Video_Games_v1_00.tsv', sep=\"\\t\", error_bad_lines=False)\n",
    "data_dc = pd.read_csv(project_path + '/data/amazon_reviews_us_Digital_Video_Games_v1_00.tsv', sep=\"\\t\", error_bad_lines=False)\n",
    "data_raw = pd.concat([data_hc,data_dc], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null data\n",
    "print(data_raw.isnull().sum(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing data, since the amount of missing data is very low\n",
    "data = data_raw.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check data quality and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check duplicates\n",
    "print(data[\"marketplace\"].value_counts()) #Only data from us marketplace, so we can drop the row\n",
    "print(\"number of duplicated customer ids = \", len(data[data['customer_id'].duplicated() == True])) #most likely because customers ordered multiple items\n",
    "print(\"number of duplicated review ids = \", len(data[data['review_id'].duplicated() == True])) \n",
    "#has to be 0 in order to ensure the ID is unique, i think we can drop this row as well in this case\n",
    "#placeholder for code that shows if product_id, product_title and product_parent are fully correlated\n",
    "print(\"product_category: \", data[\"product_category\"].value_counts())\n",
    "print(\"star rating: \", data[\"star_rating\"].value_counts())\n",
    "print(\"vines: \",data[\"vine\"].value_counts())\n",
    "print(\"verified_purchases: \",data[\"verified_purchase\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check corr\n",
    "round(data.corr(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the rows we do not need for this analysis or our model\n",
    "to_drop = [\"marketplace\"] # \"review_id\", \"product_id\", \"product_parent\"\n",
    "data = data.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reviews per product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_per_product = data.groupby([\"product_id\"])[\"review_id\"].nunique().sort_values().reset_index().rename({\"review_id\":\"num_of_reviews\"}, axis=1)\n",
    "\n",
    "reviews_per_product.tail(1000).plot()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_per_product[\"num_of_reviews\"].quantile([0.01,0.1,0.25, 0.5,0.75,0.9,0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### countplot of various data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=data[\"product_category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=data[\"star_rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=data[\"verified_purchase\"])\n",
    "#there are a lot of non-verified purchases \n",
    "#let's look at how the rating distribution of these reviews looks like compared to the verified ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('verified_purchase').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative pie chat of verified and non-verified purchase\n",
    "def label_function(val):\n",
    "    return f'{val / 100 * len(data):,.0f}\\n{val:.2f}%'\n",
    "\n",
    "figsize = (10, 5)\n",
    "\n",
    "data.groupby('verified_purchase').size().plot(kind='pie', \n",
    "                                              autopct=label_function, \n",
    "                                              textprops={'fontsize': 10},\n",
    "                                              cmap = cm.get_cmap('Pastel1'))\n",
    "\n",
    "plt.ylabel('', fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(x=data[data[\"verified_purchase\"]==\"Y\"][\"star_rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative pie chat of verified and non-verified purchase\n",
    "def label_function(val):\n",
    "    return f'{val / 100 * len(data):,.0f}\\n{val:.2f}%'\n",
    "\n",
    "figsize = (10, 5)\n",
    "\n",
    "data[data[\"verified_purchase\"]==\"Y\"].groupby('star_rating').size().plot(kind='pie', \n",
    "                                              autopct=label_function, \n",
    "                                              textprops={'fontsize': 8},\n",
    "                                              cmap = cm.get_cmap('Pastel1'))\n",
    "\n",
    "plt.ylabel('', fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative pie chat of verified and non-verified purchase\n",
    "def label_function(val):\n",
    "    return f'{val / 100 * len(data):,.0f}\\n{val:.2f}%'\n",
    "\n",
    "figsize = (10, 5)\n",
    "\n",
    "data[data[\"verified_purchase\"]==\"N\"].groupby('star_rating').size().plot(kind='pie', \n",
    "                                              autopct=label_function, \n",
    "                                              textprops={'fontsize': 8},\n",
    "                                              cmap = cm.get_cmap('Pastel1'))\n",
    "\n",
    "plt.ylabel('', fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=data[data[\"verified_purchase\"]==\"N\"][\"star_rating\"])\n",
    "#there are a lot more lower ratings in comparison. \n",
    "#It is possible that customers were so unhappy, that they created a 2nd account just to review the game negatively again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are definitely more hard-copy sales than digital sales, let's look at the ratings from the reviews for each one\n",
    "sns.countplot(x=data[data[\"product_category\"]==\"Video Games\"][\"star_rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=data[data[\"product_category\"]==\"Digital_Video_Games\"][\"star_rating\"])\n",
    "#we can see from this simple analysis, that there are a lot more 1-star reviews for digital products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rating problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"rating_problems\"] = data[\"star_rating\"].apply(lambda x: False if x in [1,2,3,4,5,\"1\", \"2\", \"3\", \"4\", \"5\" ] else True) \n",
    "data[\"star_rating\"].value_counts(normalize=1)\n",
    "data[\"rating_problems\"].value_counts(normalize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data[\"rating_problems\"] != True]\n",
    "data[\"star_rating\"] = data[\"star_rating\"].astype(\"int\")\n",
    "sns.countplot(x=data[\"star_rating\"]) # Data is very imbalanced across classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reviews over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_over_time = data.groupby(\"review_date\").agg({\"review_id\":\"count\"}).plot(kind=\"line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rev_prod_per_rating = data.groupby(\"star_rating\").agg({\"review_id\":lambda x: x.nunique(), \"product_id\": lambda x: x.nunique()} )\n",
    "num_rev_prod_per_rating[\"rev_per_prod\"] = num_rev_prod_per_rating.apply(lambda x: x[\"review_id\"] / x[\"product_id\"], axis=1)\n",
    "num_rev_prod_per_rating[\"rev_per_prod\"].plot(kind=\"bar\", title=\"Reviews per product\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby([\"star_rating\", \"verified_purchase\"])[\"review_id\"].count().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 10 most rated titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"product_title\"].value_counts().head(10).plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 titles where the reviews recieved the most votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"product_title\", \"total_votes\"]].nlargest(10, [\"total_votes\"]).plot(x=\"product_title\", y=\"total_votes\", kind=\"barh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 titles have the most 5-star reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"star_rating\"] == 5][\"product_title\"].value_counts().head(10).plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 titles with the lowest rated reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"star_rating\"] == 1][\"product_title\"].value_counts().head(10).plot(kind=\"barh\")\n",
    "#that's where SimCity went, reviewers did not like this game at all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 games with the most helpful reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"product_title\", \"helpful_votes\"]].nlargest(10, [\"helpful_votes\"]).plot(x=\"product_title\", y=\"helpful_votes\", kind=\"barh\")\n",
    "#Customers found reviews of SimCity the most helpful allthough the game also had a lot of bad reviews. this again shows that this title was highly controversial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### tokenization and stemming of review_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "stemmer = EnglishStemmer()\n",
    "\n",
    "\n",
    "stop_words.update([\"car\", \"work\", \"product\", \"install\"])\n",
    "\n",
    "def tokenization_and_stemming(text):\n",
    "    tokens = []\n",
    "    # exclude stop words and tokenize the document, generate a list of string \n",
    "    for word in word_tokenize(text):\n",
    "        if word.lower() not in stop_words:\n",
    "            tokens.append(word.lower())\n",
    "\n",
    "    filtered_tokens = []\n",
    "    \n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if token.isalpha(): # filter out non alphabet words like emoji\n",
    "            filtered_tokens.append(token)\n",
    "            \n",
    "    # stemming\n",
    "    # Removes ing also in anything ...\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return_string = \" \".join(stems)\n",
    "    \n",
    "    return return_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review_body = data.dropna(subset=['review_body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review_body[\"processed_reviews\"] = df_review_body[\"review_body\"].apply(lambda x: tokenization_and_stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review_body.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word cloud of processed_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed_reviews = data.dropna(subset=\"processed_reviews\")\n",
    "processed_review_string = df_processed_reviews.groupby(\"star_rating\").aggregate({\"processed_reviews\":lambda x: \" \\n \".join(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wc_for_rating(rating):\n",
    "    wordcloud = WordCloud(collocations=True).generate(processed_review_string.loc[rating][0][1:5000000].replace(\"one\", \"\").replace(\"use\", \"\").replace(\" br \", \" \").replace(\"car\", \"\").replace(\"work\", \"\"))\n",
    "    # Display the generated image:\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_for_rating(1)\n",
    "wc_for_rating(2)\n",
    "wc_for_rating(3)\n",
    "wc_for_rating(4)\n",
    "wc_for_rating(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --- From here new 2023/01/12  ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check corr\n",
    "round(data.corr(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the rows we do not need for this analysis or our model\n",
    "to_drop = [\"marketplace\"] # \"review_id\", \"product_id\", \"product_parent\"\n",
    "data = data.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to lower case\n",
    "data['review_body'] = data['review_body'].astype(str).str.lower()\n",
    "data['review_headline'] = data['review_headline'].astype(str).str.lower()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing punctuation and converting to lower case\n",
    "import re\n",
    "import string\n",
    "\n",
    "def text_clean1(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation),'',text)\n",
    "    return text\n",
    "\n",
    "cleaned1 = lambda x: text_clean1(x)\n",
    "\n",
    "#sample data to test code\n",
    "data_subsample = data.iloc[0:100]\n",
    "\n",
    "# using function on columns\n",
    "data_subsample['cleaned_reviewheadline'] = data_subsample['review_headline'].apply(cleaned1)\n",
    "data_subsample['cleaned_reviewbody'] = data_subsample['review_body'].apply(cleaned1)\n",
    "\n",
    "\n",
    "#Another round of cleaning\n",
    "def text_clean2(text):\n",
    "    text = re.sub('\\n','', text)\n",
    "    return text\n",
    "\n",
    "cleaned2 = lambda x: text_clean2(x)\n",
    "data_subsample['cleaned_reviewheadline'] = data_subsample['cleaned_reviewheadline'].apply(cleaned2)\n",
    "data_subsample['cleaned_reviewbody'] = data_subsample['cleaned_reviewbody'].apply(cleaned2)\n",
    "\n",
    "data_subsample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')\n",
    "data_subsample['cleaned_reviewbody'] = data_subsample['cleaned_reviewbody'].apply(lambda words: ' '.join(word.lower() for word in words.split()if word not in stopwords))\n",
    "data_subsample.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return ' '.join([lemmatizer.lemmatize(w) for w in text.split(' ')])\n",
    "\n",
    "data_subsample['tokenized_reviewbody'] = data_subsample['cleaned_reviewbody'].apply(lemmatize_text)\n",
    "data_subsample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'w+')\n",
    "data_subsample['tokenizedbody'] = data_subsample['cleaned_reviewbody'].apply(tokenizer.tokenize)\n",
    "data_subsample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Exploratory Analysis\n",
    "data_subsample['word_length'] = data_subsample['cleaned_reviewbody'].str.split().str.len()\n",
    "data_subsample.head()\n",
    "def sentiment(row):\n",
    "    if row['star_rating'] == 5:\n",
    "        return \"Positive\"\n",
    "    elif row['star_rating'] == 1:\n",
    "        return \"Negative\"\n",
    "    elif  1 < row['star_rating'] < 5:\n",
    "        return \"Inbetween\"\n",
    "    else:\n",
    "        return \"Undefined\"\n",
    "    \n",
    "\n",
    "data_subsample['star_sentiment'] = data_subsample.apply(sentiment,axis =1)\n",
    "data_subsample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating text length\n",
    "data_subsample[[\"word_length\", \"star_sentiment\"]].hist(bins=20, figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "plt.figure(figsize=(15,7))\n",
    "cmap = ['red', 'green','yellow']\n",
    "labels = ['Negative', 'Positive', 'Inbetween']\n",
    "\n",
    "for label,clr in zip(labels,cmap):\n",
    "    sns.kdeplot(data_subsample.loc[(data_subsample['star_sentiment'] == label),'word_length'], color=clr, shade=True, label=label)\n",
    "    plt.xlabel('Text Length')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing punctuation and converting to lower case\n",
    "import re\n",
    "import string\n",
    "\n",
    "def text_clean1(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation),'',text)\n",
    "    return text\n",
    "\n",
    "cleaned1 = lambda x: text_clean1(x)\n",
    "\n",
    "\n",
    "# using function on columns\n",
    "data['cleaned_reviewheadline'] = data['review_headline'].apply(cleaned1)\n",
    "data['cleaned_reviewbody'] = data['review_body'].apply(cleaned1)\n",
    "\n",
    "\n",
    "#Another round of cleaning\n",
    "def text_clean2(text):\n",
    "    text = re.sub('\\n','', text)\n",
    "    return text\n",
    "\n",
    "cleaned2 = lambda x: text_clean2(x)\n",
    "data['cleaned_reviewheadline'] = data['cleaned_reviewheadline'].apply(cleaned2)\n",
    "data['cleaned_reviewbody'] = data['cleaned_reviewbody'].apply(cleaned2)\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')\n",
    "data['cleaned_reviewbody'] = data['cleaned_reviewbody'].apply(lambda words: ' '.join(word.lower() for word in words.split()if word not in stopwords))\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return ' '.join([lemmatizer.lemmatize(w) for w in text.split(' ')])\n",
    "\n",
    "data['tokenized_reviewbody'] = data['cleaned_reviewbody'].apply(lemmatize_text)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Exploratory Analysis\n",
    "data['word_length'] = data['cleaned_reviewbody'].str.split().str.len()\n",
    "data.head()\n",
    "def sentiment(row):\n",
    "    if row['star_rating'] == 5:\n",
    "        return \"Positive\"\n",
    "    elif row['star_rating'] == 1:\n",
    "        return \"Negative\"\n",
    "    elif  1 < row['star_rating'] < 5:\n",
    "        return \"Inbetween\"\n",
    "    else:\n",
    "        return \"Undefined\"\n",
    "    \n",
    "\n",
    "data['star_sentiment'] = data.apply(sentiment,axis =1)\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "fig, ax = plt.subplots()\n",
    "cmap = ['red', 'green','yellow']\n",
    "labels = ['Negative', 'Positive', 'Inbetween']\n",
    "\n",
    "for label,clr in zip(labels,cmap):\n",
    "    sns.kdeplot(data.loc[(data['star_sentiment'] == label),'word_length'], ax=ax, color=clr, shade=True, label=label)\n",
    "    ax.set_xlim(0,199)\n",
    "    plt.xlabel('Text Length')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Easy and approximate detection of english by scanning reviews for \" the \", \" and \", \"but\"\n",
    "import numpy as np\n",
    "english_words = [\"great\", \"game\", \" and \", \"the \", \"but \", \"good\", \" bad \", \" this \", \" my \", \"awesome\", \"love\", \"have\", \" be \", \" it \", \" was \",\\\n",
    "     \" an \", \"they\", \"did\", \"not\", \"quality\", \"poor\", \"perfect\", \"it \", \"for\", \"his\", \"work\", \"recommend\", \"nice\", \"excellent\", \"fantastic\", \"issues\", \"very\", \"my\", \"gift\",\\\n",
    "        \"with\", \"ok\", \"can\", \"just\", \"you\", \"memory\", \"thanks\", \"now\", \"uses\", \"fun\", \"too\", \"decent\", \"problems\", \"good\", \"want\", \"please\", \"want\", \"there\", \"are\", \"product\", \"believ\",\\\n",
    "                \"like\", \"again\", \"only\", \"much \", \"please\", \" i \", \"buy\", \"what\", \"money\", \"waste\", \" at \", \"able\", \"worth\", \"try\", \"epic\", \"amazing\",  \"play\", \"brilliant\", \"don't\",\\\n",
    "                        \"better\", \" way\", \"about\", \"stupid\", \" run\", \"bring\", \"version\", \" of \", \" as \", \"it's\", \"ever\", \" me \", \"how\", \" by \"]\n",
    "# Could use stopwords, but running time increases with every list member several seconds\n",
    "\n",
    "data=data.dropna(subset=\"review_body\")\n",
    "data[\"language\"] = data[\"review_body\"].apply(lambda x: \"EN\" if (np.any([s in x.lower() for s in english_words])) else \"OTHER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.value_counts(\"language\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"language\"]!=\"EN\"][\"review_body\"].tail(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "stemmer = EnglishStemmer()\n",
    "\n",
    "\n",
    "stop_words.update([\"car\", \"work\", \"product\", \"install\"])\n",
    "\n",
    "def tokenization_and_stemming(text):\n",
    "    tokens = []\n",
    "    # exclude stop words and tokenize the document, generate a list of string \n",
    "    for word in word_tokenize(text):\n",
    "        if word.lower() not in stop_words:\n",
    "            tokens.append(word.lower())\n",
    "\n",
    "    filtered_tokens = []\n",
    "    \n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if token.isalpha(): # filter out non alphabet words like emoji\n",
    "            filtered_tokens.append(token)\n",
    "            \n",
    "    # stemming\n",
    "    # Removes ing also in anything ...\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return_string = \" \".join(stems)\n",
    "    \n",
    "    return return_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.dropna(subset=['review_body'])\n",
    "data_en = data[data[\"language\"]==\"EN\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processed_reviews = data_en[\"review_body\"].apply(lambda x: tokenization_and_stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_reviews.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_en[\"processed_reviews\"] = processed_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "data_en.to_pickle(r\"../../data/data_en.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = processed_reviews.apply(lambda x: x.split(\" \"))\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list = [item for sublist in list(tokens) for item in sublist] \n",
    "token_string = \" \".join(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def return_word_occurences(token_string, stopwords_in = None):\n",
    "    vectorizer = CountVectorizer(stop_words = stopwords_in)\n",
    "    #vectorizer.fit_transform(token_list)\n",
    "    X = vectorizer.fit_transform([token_string])\n",
    "    #vocab = vectorizer.vocabulary_\n",
    "    words = vectorizer.get_feature_names_out()\n",
    "    word_occurences = X.toarray().sum(axis=0)\n",
    "    word_occurences_dict = dict(zip(words, word_occurences))\n",
    "    sorted_occurences = sorted(word_occurences_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_occurences_initial = return_word_occurences(token_string)\n",
    "sorted_occurences_initial\n",
    "\n",
    "pd.DataFrame(sorted_occurences_initial).to_csv(r\"../../data/word_occurences.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_cv = set(stopwords.words('english'))\n",
    "stop_words_cv.update([\"game\", \"br\", \"play\", \"get\", \"one\", \"would\", \"make\", \"first\"])\n",
    "\n",
    "#Update inspired by word cloud per rating class\n",
    "stop_words_cv_enh = stop_words_cv\n",
    "stop_words_cv_enh.update([\"like\", \"control\", \"time\"])\n",
    "\n",
    "sorted_occurences_sw = return_word_occurences(token_string, stopwords_in=stop_words_cv)\n",
    "sorted_occurences_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.dropna(subset=\"processed_reviews\")\n",
    "processed_review_string = data_en.groupby(\"star_rating\").aggregate({\"processed_reviews\":lambda x: \" \".join(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_review_string.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wc_for_rating(rating, stopwords_in = None, max_words = 100, collocations = False):\n",
    "    plt.figure(figsize = (20,20))\n",
    "    wordcloud = WordCloud(collocations=collocations, stopwords = stopwords_in, max_words = max_words).generate(processed_review_string.loc[rating][0])\n",
    "    # Display the generated image:\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_for_rating(1, stopwords_in= stop_words_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wc_for_rating(1, stopwords_in= stop_words_cv)\n",
    "wc_for_rating(2, stopwords_in= stop_words_cv)\n",
    "wc_for_rating(3, stopwords_in= stop_words_cv)\n",
    "wc_for_rating(4, stopwords_in= stop_words_cv)\n",
    "wc_for_rating(5, stopwords_in= stop_words_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_for_rating(1, stopwords_in= stop_words_cv_enh)\n",
    "wc_for_rating(2, stopwords_in= stop_words_cv_enh)\n",
    "wc_for_rating(3, stopwords_in= stop_words_cv_enh)\n",
    "wc_for_rating(4, stopwords_in= stop_words_cv_enh)\n",
    "wc_for_rating(5, stopwords_in= stop_words_cv_enh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    data.to_csv(r\"D:\\DSProject\\VideoGames_transformed.csv\")\n",
    "else:\n",
    "    data = pd.read_csv(r\"D:\\DSProject\\amazon_reviews_us_Automotive_v1_00_transformed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.dropna(subset=\"processed_reviews\")\n",
    "# Lots of foreign languages in the dataset, thus filter for marketplace = US\n",
    "tokens = processed_reviews.apply(lambda x: x.split(\" \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list = [item for sublist in list(tokens) for item in sublist] \n",
    "token_string = \" \".join(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_string = \" \".join(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def return_word_occurences(token_string, stopwords_in = None):\n",
    "    vectorizer = CountVectorizer(stop_words = stopwords_in)\n",
    "    #vectorizer.fit_transform(token_list)\n",
    "    X = vectorizer.fit_transform([token_string])\n",
    "    #vocab = vectorizer.vocabulary_\n",
    "    words = vectorizer.get_feature_names_out()\n",
    "    word_occurences = X.toarray().sum(axis=0)\n",
    "    word_occurences_dict = dict(zip(words, word_occurences))\n",
    "    sorted_occurences = sorted(word_occurences_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    return sorted_occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_occurences_initial = return_word_occurences(token_string)\n",
    "sorted_occurences_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_occurences_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_cv = set(stopwords.words('english'))\n",
    "stop_words_cv.update([\"game\", \"br\", \"play\", \"get\", \"one\", \"would\", \"make\"])\n",
    "\n",
    "sorted_occurences_sw = return_word_occurences(token_string, stopwords_in=stop_words_cv)\n",
    "sorted_occurences_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_occurences_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "r = re.compile(r\"[a-zA-Z]+\")\n",
    "test = r.match('çáêôæíô')\n",
    "test2 = r.match('windshiield')\n",
    "\n",
    "token_list_an = [item for item in token_list_us if not (r.match(item) is None)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the sample data for testing code (faster)\n",
    "# data_test = data.sample(frac=.1)\n",
    "data_test = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special characters\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function that removes special characters\n",
    "def remove_special_characters(text):\n",
    "    return re.sub(\"[^A-Za-z]+\", \" \", text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special characters in the string\n",
    "data_test['review_headline_wo_punctuations']= data_test['review_headline'].apply(lambda x:remove_special_characters(x))\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[(data_test['review_headline_wo_punctuations']!= data_test['review_headline']) == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define remove stopwords function\n",
    "def remove_stopwords(df, col):\n",
    "    s = df[col].str.lower() # stopwords in the package are all in lower case\n",
    "    for word in stopwords.words('english'):\n",
    "        s = s.str.replace(\"\\\\b\" + word + \"\\\\b\", \" \", regex=True)\n",
    "#         print(word + \" \", end=\"\")\n",
    "    return s.str.replace(\"\\\\s+\", \" \", regex=True) # .strip()\n",
    "\n",
    "# # define function: remove word if the length = 1\n",
    "# def remove_single_word(s):\n",
    "#     if len(s) <= 1:\n",
    "#         return ''\n",
    "#     else:\n",
    "#         return s\n",
    "\n",
    "# define generate_N_grams function\n",
    "def generate_N_grams(text, ngram):\n",
    "    text = text.strip()\n",
    "    words = text.split(\" \")\n",
    "#     print(words)\n",
    "    if len(words) < ngram:                  \n",
    "        return '_'.join(words) \n",
    "    else: \n",
    "        temp=zip(*[words[i:] for i in range(0,ngram)])\n",
    "        ans=['_'.join(word) for word in temp]\n",
    "        return \" \".join(ans).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for word in stopwords.words('english'):\n",
    "#     print(word)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Question: if text length is smaller than ngram, it will return empty string (See example below). How to include them into analyse? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function\n",
    "print(generate_N_grams(\"Horrible Gave a great trilogy a horrible ending\",2))\n",
    "# print(generate_N_grams(\"Horrible Gave a great trilogy a horrible ending\",1))\n",
    "# print(*ngrams(\"Horrible Gave a great trilogy a horrible ending\".split(\" \"), 2))\n",
    "\n",
    "# remove_stopwords(df_train[df_train.star_rating==5][:5], \"review_headline_wo_punctuations\")\n",
    "# df_train[df_train.star_rating==5][:5]['review_headline_wo_punctuations'].str.replace(\"\\\\band\\\\b\", \"\")\n",
    "# print(generate_N_grams(\" best\",2)) # _best\n",
    "# print(generate_N_grams(\"love \",2)) # love_\n",
    "generate_N_grams(\"awesome text\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove stopwords \n",
    "data_test['review_headline_wo_punctuations'] = remove_stopwords(data_test, 'review_headline_wo_punctuations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.head(3).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# chec na in the data\n",
    "print(data_test.review_headline.isna().sum())\n",
    "print(data_test.star_rating.isna().sum())\n",
    "# no na data in both columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only star rating 5 reviews contrain text \"five stars\" in review\n",
    "df_train[df_train['review_headline'].str.contains(\"five stars\")==True]['star_rating'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_test['star_rating'].values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_test['review_headline_wo_punctuations'].values\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(x_train,x_test,y_train,y_test)=train_test_split(x,y,test_size=0.4)\n",
    "print(\"x_train shape: \", x_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"x_test shape: \", x_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_train = pd.DataFrame(x_train)\n",
    "df_x_train = df_x_train.rename(columns={0:'review_headline'})\n",
    "\n",
    "df_y_train = pd.DataFrame(y_train)\n",
    "df_y_train = df_y_train.rename(columns={0:'star_rating'})\n",
    "\n",
    "df_train = pd.concat([df_x_train,df_y_train],axis=1)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_test = pd.DataFrame(x_test)\n",
    "df_x_test = df_x_test.rename(columns={0:'review_headline'})\n",
    "\n",
    "df_y_test = pd.DataFrame(y_test)\n",
    "df_y_test = df_y_test.rename(columns={0:'star_rating'})\n",
    "\n",
    "df_test = pd.concat([df_x_test,df_y_test],axis=1)\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define functions for bigrams and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions for bigrams and trigrams analysis\n",
    "def generate_N_grams_df(df, column_y, value_y, column_x, n_grams, dict_result):\n",
    "    for text in df[df[column_y] == value_y][column_x]:\n",
    "        ngram = generate_N_grams(text, n_grams)\n",
    "        if len(ngram) == 1 and ngram[0] == \"\": # skip empty string\n",
    "            pass\n",
    "        if len(generate_N_grams(text, n_grams)) < n_grams:\n",
    "            dict_result[text]+=1\n",
    "        else:\n",
    "            for word in generate_N_grams(text, n_grams).split(\" \"):\n",
    "                dict_result[word]+=1\n",
    "    \n",
    "    df_result = pd.DataFrame.from_dict(dict_result, orient = 'index')\n",
    "    df_result = df_result.rename(columns={0:'# words'}).sort_values(by=['# words']).reset_index()\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "n_grams = 1\n",
    "\n",
    "rating_5 = defaultdict(int)\n",
    "rating_4 = defaultdict(int)\n",
    "rating_3 = defaultdict(int)\n",
    "rating_2 = defaultdict(int)\n",
    "rating_1 = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create string with n-grams\n",
    "# get the count of every word in both the columns of df_train and df_test dataframes where star_rating=5\n",
    "for text in df_train[df_train.star_rating==5].review_headline:\n",
    "    for word in generate_N_grams(text, n_grams).split(\" \"):\n",
    "        rating_5[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dict to df\n",
    "df_rating_5 = pd.DataFrame.from_dict(rating_5, orient = 'index')\n",
    "df_rating_5 = df_rating_5.rename(columns={0:'# words'}).sort_values(by=['# words']).reset_index()\n",
    "df_rating_5.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create string with n-grams\n",
    "# get the count of every word in both the columns of df_train and df_test dataframes where star_rating=1\n",
    "for text in df_train[df_train.star_rating==1].review_headline:\n",
    "    for word in generate_N_grams(text, n_grams).split(\" \"):\n",
    "        rating_1[word]+=1\n",
    "\n",
    "# convert dict to df\n",
    "df_rating_1 = pd.DataFrame.from_dict(rating_1, orient = 'index')\n",
    "df_rating_1 = df_rating_1.rename(columns={0:'# words'}).sort_values(by=['# words']).reset_index()\n",
    "df_rating_1.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in df_train[df_train.star_rating==2].review_headline:\n",
    "    for word in generate_N_grams(text, n_grams).split(\" \"):\n",
    "        rating_2[word]+=1\n",
    "\n",
    "# convert dict to df\n",
    "df_rating_2 = pd.DataFrame.from_dict(rating_2, orient = 'index')\n",
    "df_rating_2 = df_rating_2.rename(columns={0:'# words'}).sort_values(by=['# words']).reset_index()\n",
    "df_rating_2.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for text in df_train[df_train.star_rating==3].review_headline:\n",
    "    for word in generate_N_grams(text, n_grams).split(\" \"):\n",
    "        rating_3[word]+=1\n",
    "\n",
    "# convert dict to df\n",
    "df_rating_3 = pd.DataFrame.from_dict(rating_3, orient = 'index')\n",
    "df_rating_3 = df_rating_3.rename(columns={0:'# words'}).sort_values(by=['# words']).reset_index()\n",
    "df_rating_3.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for text in df_train[df_train.star_rating==4].review_headline:\n",
    "    for word in generate_N_grams(text, n_grams).split(\" \"):\n",
    "        rating_4[word]+=1\n",
    "\n",
    "# convert dict to df\n",
    "df_rating_4 = pd.DataFrame.from_dict(rating_4, orient = 'index')\n",
    "df_rating_4 = df_rating_4.rename(columns={0:'# words'}).sort_values(by=['# words']).reset_index()\n",
    "df_rating_4.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#focus on more frequently occuring words for top and lowest ratings\n",
    "#sort in DO wrt 2nd column in each of top and lowest ratings\n",
    "df_rating_5['index'][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(16,4))\n",
    "plt.bar(df_rating_5['index'][-10:], df_rating_5['# words'][-10:], color ='green', width = 0.4)\n",
    "plt.xlabel(\"Words in star_rating 5 DF\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 10 words in star_rating 5 DF-UNIGRAM ANALYSIS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(16,4))\n",
    "plt.bar(df_rating_4['index'][-10:], df_rating_4['# words'][-10:], color ='green', width = 0.4)\n",
    "plt.xlabel(\"Words in star_rating 4 DF\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 10 words in star_rating 4 DF-UNIGRAM ANALYSIS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(16,4))\n",
    "plt.bar(df_rating_3['index'][-10:], df_rating_3['# words'][-10:], color ='green', width = 0.4)\n",
    "plt.xlabel(\"Words in star_rating 3 DF\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 10 words in star_rating 3 DF-UNIGRAM ANALYSIS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(16,4))\n",
    "plt.bar(df_rating_2['index'][-10:], df_rating_2['# words'][-10:], color ='green', width = 0.4)\n",
    "plt.xlabel(\"Words in star_rating 2 DF\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 10 words in star_rating 2 DF-UNIGRAM ANALYSIS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(16,4))\n",
    "plt.bar(df_rating_1['index'][-10:], df_rating_1['# words'][-10:], color ='green', width = 0.4)\n",
    "plt.xlabel(\"Words in star_rating 1 DF\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 10 words in star_rating 1 DF-UNIGRAM ANALYSIS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The result of unigram is similar to wordcloud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative directly use ngrams package --> only works with single string\n",
    "# get individual words\n",
    "# tokenized = text.split()\n",
    "\n",
    "# for text in df_train[df_train.star_rating==5].review_headline_wo_punctuations:\n",
    "#     print(text)\n",
    "#     tokenized = text.split()\n",
    "#     print(tokenized)\n",
    "#     for word in tokenized:\n",
    "#         rating_5_v2['word']\n",
    "#         print(ngrams(tokenized, 2))\n",
    "#     stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = ngrams(tokenized, 2)\n",
    "# collections.Counter(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "rating_5 = defaultdict(int)\n",
    "rating_4 = defaultdict(int)\n",
    "rating_3 = defaultdict(int)\n",
    "rating_2 = defaultdict(int)\n",
    "rating_1 = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_5 = generate_N_grams_df(df = data_test, column_y = \"star_rating\", value_y = 5, \n",
    "                    column_x = \"review_headline\", n_grams = 2, \n",
    "                    dict_result = rating_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_5.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(16,4))\n",
    "plt.bar(df_rating_5['index'][-10:], df_rating_5['# words'][-10:], color ='green', width = 0.4)\n",
    "plt.xlabel(\"Words in star_rating 5 DF\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 10 words in star_rating 5 DF-UNIGRAM ANALYSIS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_4 = generate_N_grams_df(df = data_test, column_y = \"star_rating\", value_y = 4, \n",
    "                    column_x = \"review_headline\", n_grams = 2, \n",
    "                    dict_result = rating_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_4.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(16,4))\n",
    "plt.bar(df_rating_4['index'][-10:], df_rating_4['# words'][-10:], color ='green', width = 0.4)\n",
    "plt.xlabel(\"Words in star_rating 4 DF\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 10 words in star_rating 4 DF-UNIGRAM ANALYSIS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_3 = generate_N_grams_df(df = df_train, column_y = \"star_rating\", value_y = 3, \n",
    "                    column_x = \"review_headline\", n_grams = 2, \n",
    "                    dict_result = rating_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_3.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(16,4))\n",
    "plt.bar(df_rating_3['index'][-10:], df_rating_3['# words'][-10:], color ='green', width = 0.4)\n",
    "plt.xlabel(\"Words in star_rating 3 DF\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 10 words in star_rating 3 DF-UNIGRAM ANALYSIS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_rating_2 = generate_N_grams_df(df = df_train, column_y = \"star_rating\", value_y = 2, \n",
    "                    column_x = \"review_headline\", n_grams = 2, \n",
    "                    dict_result = rating_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(16,4))\n",
    "plt.bar(df_rating_2['index'][-10:], df_rating_2['# words'][-10:], color ='green', width = 0.4)\n",
    "plt.xlabel(\"Words in star_rating 2 DF\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 10 words in star_rating 2 DF-UNIGRAM ANALYSIS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_rating_1 = generate_N_grams_df(df = df_train[df_train['star_rating'] == 1], \n",
    "                                  column_y = \"star_rating\", value_y = 1, \n",
    "                                  column_x = \"review_headline\", n_grams = 2, \n",
    "                                  dict_result = rating_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(16,4))\n",
    "plt.bar(df_rating_1['index'][-10:], df_rating_1['# words'][-10:], color ='green', width = 0.4)\n",
    "plt.xlabel(\"Words in star_rating 1 DF\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 10 words in star_rating 1 DF-UNIGRAM ANALYSIS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "rating_5 = defaultdict(int)\n",
    "rating_4 = defaultdict(int)\n",
    "rating_3 = defaultdict(int)\n",
    "rating_2 = defaultdict(int)\n",
    "rating_1 = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_5 = generate_N_grams_df(df = data_test, column_y = \"star_rating\", value_y = 5, \n",
    "                    column_x = \"review_headline\", n_grams = 3, \n",
    "                    dict_result = rating_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_rating_4 = generate_N_grams_df(df = data_test, column_y = \"star_rating\", value_y = 4, \n",
    "                    column_x = \"review_headline\", n_grams = 3, \n",
    "                    dict_result = rating_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_3 = generate_N_grams_df(df = data_test, column_y = \"star_rating\", value_y = 3, \n",
    "                    column_x = \"review_headline_wo_punctuations\", n_grams = 3, \n",
    "                    dict_result = rating_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_rating_2 = generate_N_grams_df(df = data_test, column_y = \"star_rating\", value_y = 2, \n",
    "                    column_x = \"review_headline_wo_punctuations\", n_grams = 3, \n",
    "                    dict_result = rating_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_rating_1 = generate_N_grams_df(df = data_test, column_y = \"star_rating\", value_y = 1, \n",
    "                    column_x = \"review_headline_wo_punctuations\", n_grams = 3, \n",
    "                    dict_result = rating_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(16,4))\n",
    "plt.bar(df_rating_5['index'][-10:], df_rating_5['# words'][-10:], color ='green', width = 0.4)\n",
    "plt.xlabel(\"Words in star_rating 5 DF\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 10 words in star_rating 5 DF-TRIGRAM ANALYSIS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(16,4))\n",
    "plt.bar(df_rating_4['index'][-10:], df_rating_4['# words'][-10:], color ='green', width = 0.4)\n",
    "plt.xlabel(\"Words in star_rating 4 DF\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 10 words in star_rating 4 DF-TRIGRAM ANALYSIS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(16,4))\n",
    "plt.bar(df_rating_3['index'][-10:], df_rating_3['# words'][-10:], color ='green', width = 0.4)\n",
    "plt.xlabel(\"Words in star_rating 3 DF\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 10 words in star_rating 3 DF-TRIGRAM ANALYSIS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_3[(df_rating_3['index'].str.strip() == '') == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_3 = df_rating_3[(df_rating_3['index'].str.strip() == '') == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_3.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the top 10 contains empty space -- > drop it (need to modify the n_gram function)\n",
    "plt.figure(1,figsize=(16,4))\n",
    "plt.bar(df_rating_3['index'][-10:], df_rating_3['# words'][-10:], color ='green', width = 0.4)\n",
    "plt.xlabel(\"Words in star_rating 3 DF\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 10 words in star_rating 3 DF-TRIGRAM ANALYSIS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(16,4))\n",
    "plt.bar(df_rating_2['index'][-10:], df_rating_2['# words'][-10:], color ='green', width = 0.4)\n",
    "plt.xlabel(\"Words in star_rating 2 DF\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 10 words in star_rating 2 DF-TRIGRAM ANALYSIS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_2 = df_rating_2[(df_rating_2['index'].str.strip() == '') == False]\n",
    "df_rating_2.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(16,4))\n",
    "plt.bar(df_rating_2['index'][-10:], df_rating_2['# words'][-10:], color ='green', width = 0.4)\n",
    "plt.xlabel(\"Words in star_rating 2 DF\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 10 words in star_rating 2 DF-TRIGRAM ANALYSIS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(16,4))\n",
    "plt.bar(df_rating_1['index'][-10:], df_rating_1['# words'][-10:], color ='green', width = 0.4)\n",
    "plt.xlabel(\"Words in star_rating 1 DF\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 10 words in star_rating 1 DF-TRIGRAM ANALYSIS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating_1 = df_rating_1[(df_rating_1['index'].str.strip() == '') == False]\n",
    "df_rating_1.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(16,4))\n",
    "plt.bar(df_rating_1['index'][-10:], df_rating_1['# words'][-10:], color ='green', width = 0.4)\n",
    "plt.xlabel(\"Words in star_rating 1 DF\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 10 words in star_rating 1 DF-TRIGRAM ANALYSIS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To-Do <br>\n",
    "the result of trigram makes most sense. <br>\n",
    "As next step, a matrix for further ML-analysis (for example naive bayes [Link](https://towardsdatascience.com/text-classification-using-naive-bayes-theory-a-working-example-2ef4b7eb7d5a))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['review_headline_ngrams'] = df_test['review_headline_wo_punctuations'].apply(lambda x: generate_N_grams(x, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_final = df_test[['star_rating', 'review_headline_ngrams']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df_test_final.review_headline_ngrams.values.tolist()\n",
    "corpus[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions for bigrams and trigrams analysis\n",
    "def generate_N_grams_df_all(df, column_x, n_grams, dict_result):\n",
    "    for text in df[column_x]:\n",
    "        ngram = generate_N_grams(text, n_grams)\n",
    "        if len(ngram) == 1 and ngram[0] == \"\": # skip empty string\n",
    "            pass\n",
    "        if len(generate_N_grams(text, n_grams)) < n_grams:\n",
    "            dict_result[text]+=1\n",
    "        else:\n",
    "            for word in generate_N_grams(text, n_grams).split(\" \"):\n",
    "                dict_result[word]+=1\n",
    "    \n",
    "    df_result = pd.DataFrame.from_dict(dict_result, orient = 'index')\n",
    "    df_result = df_result.rename(columns={0:'# words'}).sort_values(by=['# words']).reset_index()\n",
    "    \n",
    "    return df_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_result_all = defaultdict(int)\n",
    "df_result_all = generate_N_grams_df_all(df = df_test, column_x = \"review_headline_wo_punctuations\", n_grams = 3, dict_result = dict_result_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_all.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result_all[df_result_all['# words']<=5].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the tokens which appear fewer than &including 5 times\n",
    "df_result_all = df_result_all[df_result_all['# words'] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_result_all.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_filter = df_result_all['index'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(vocabulary = feature_filter)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(vectorizer.get_feature_names()[0:5])\n",
    "print(len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# problem > too many features --> not enough memory --> drop featurew with number of appearance in the db fewer than 5 times\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test matrix\n",
    "# for row in X.toarray():\n",
    "#     print(sum(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for i in X.toarray()[0]:\n",
    "#     count+=1\n",
    "#     if i != 0:\n",
    "#         print(count)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# feature_filter[2302]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "# Train the model using the training data\n",
    "model.fit(X, df_test_final.star_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "data = fetch_20newsgroups()\n",
    "text_categories = data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "1. https://www.analyticsvidhya.com/blog/2021/09/what-are-n-grams-and-how-to-implement-them-in-python/ <br>\n",
    "2. https://www.kaggle.com/code/rtatman/tutorial-getting-n-grams/notebook <br>\n",
    "3. https://towardsdatascience.com/text-classification-using-naive-bayes-theory-a-working-example-2ef4b7eb7d5a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
