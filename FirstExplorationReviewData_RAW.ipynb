{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Supply Chain -- First Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploration of metadata (without Text Mining technics)**\n",
    "Some ideas:\n",
    "\n",
    "- Response rate, influence of brand or source, verified_purchase or not\n",
    "<br> <span style=\"color: blue\"> We took a look at verified purchases and how the reviewers rated differently </span>\n",
    "\n",
    "- Distribution of scores.\n",
    "<br> <span style=\"color: blue\"> We took a look at the distribution of scores in various scenarios </span>\n",
    "\n",
    "- Influence of the marketplace or the company on the distribution of notes (hypothesis testin could be used for  this kind of analysis )\n",
    "<br> <span style=\"color: blue\"> We only have information about wether the reviewers were selected by the company or not, which we took a look at </span>\n",
    "\n",
    "- Information about the 10 most active users, with a small analysis on it (distribution of scores, response rate, company...).\n",
    "<br> <span style=\"color: blue\"> We looked at the 10 most active users </span>\n",
    "\n",
    "**Goal 2 Analysis of text (and cleaning if necessary ). You will need to complete the text mining module to be able to do this part.**\n",
    "Some ideas :\n",
    "- Analyze the punctuation according to the note\n",
    "\n",
    "- Analyze the length of the text (nb character, nb words...) according to the note.\n",
    "\n",
    "- Analyze the frequency of email addresses, links, phone numbers...\n",
    "\n",
    "- Occurrence of words, wordcloud...\n",
    "We did a word cloud already to have an overview and saw that we need to improve on stop-words\n",
    "\n",
    "- N-gram\n",
    "\n",
    "- Occurrence of some words : delivery order, return order, delivery, SAV, customer service..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "project_path = os.path.abspath(os.path.join(os.getcwd(), os.path.pardir, os.path.pardir)).replace('\\\\', '/')\n",
    "project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hc = pd.read_csv(project_path + r\"/data/amazon_reviews_us_Video_Games_v1_00.tsv\", sep=\"\\t\", error_bad_lines=False)\n",
    "data_dc = pd.read_csv(project_path + r\"/data/amazon_reviews_us_Digital_Video_Games_v1_00.tsv\", sep=\"\\t\", error_bad_lines=False)\n",
    "data_raw = pd.concat([data_hc,data_dc], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null data\n",
    "print(data_raw.isnull().sum(axis = 0) / len(data) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing data, since the amount of missing data is very low\n",
    "data = data_raw.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check data quality and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check duplicates\n",
    "print(data[\"marketplace\"].value_counts()) #Only data from us marketplace, so we can drop the row\n",
    "print(\"number of duplicated customer ids = \\n\", len(data[data['customer_id'].duplicated() == True])) #most likely because customers ordered multiple items\n",
    "print(\"number of duplicated review ids = \\n\", len(data[data['review_id'].duplicated() == True])) \n",
    "#has to be 0 in order to ensure the ID is unique, i think we can drop this row as well in this case\n",
    "#placeholder for code that shows if product_id, product_title and product_parent are fully correlated\n",
    "print(\"product_category: \\n\", data[\"product_category\"].value_counts())\n",
    "print(\"star rating: \\n\", data[\"star_rating\"].value_counts())\n",
    "print(\"vines: \\n\",data[\"vine\"].value_counts())\n",
    "print(\"verified_purchases: \\n\",data[\"verified_purchase\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the rows we do not need for this analysis or our model\n",
    "to_drop = [\"marketplace\"] # we did not drop \"review_id\", \"product_id\", \"product_parent\" for now as they might \n",
    "#still be usefull going forward\n",
    "data = data.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reviews per product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_per_product = data.groupby([\"product_id\"])[\"review_id\"].nunique().reset_index(name=\"num_of_reviews\").\\\n",
    "    sort_values(by=(['num_of_reviews']), ascending=False)\n",
    "reviews_per_product.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_per_product[\"num_of_reviews\"].quantile([0.01,0.1,0.25, 0.5,0.75,0.9,0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### countplot of various data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=data[\"product_category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=data[\"star_rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=data[\"verified_purchase\"])\n",
    "#there are a lot of non-verified purchases \n",
    "#let's look at how the rating distribution of these reviews looks like compared to the verified ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=data[data[\"verified_purchase\"]==\"Y\"][\"star_rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=data[data[\"verified_purchase\"]==\"N\"][\"star_rating\"])\n",
    "#there are a lot more lower ratings in comparison. \n",
    "#It is possible that customers were so unhappy, that they created a 2nd account just to review the game negatively again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are definitely more hard-copy sales than digital sales, let's look at the ratings from the reviews for each one\n",
    "sns.countplot(x=data[data[\"product_category\"]==\"Video Games\"][\"star_rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=data[data[\"product_category\"]==\"Digital_Video_Games\"][\"star_rating\"])\n",
    "#we can see from this simple analysis, that there are a lot more 1-star reviews for digital products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reviews over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_over_time = data.groupby(\"review_date\").agg({\"review_id\":\"count\"}).plot(kind=\"line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rev_prod_per_rating = data.groupby(\"star_rating\").agg({\"review_id\":lambda x: x.nunique(), \"product_id\": lambda x: x.nunique()} )\n",
    "num_rev_prod_per_rating[\"rev_per_prod\"] = num_rev_prod_per_rating.apply(lambda x: x[\"review_id\"] / x[\"product_id\"], axis=1)\n",
    "num_rev_prod_per_rating[\"rev_per_prod\"].plot(kind=\"bar\", title=\"Reviews per product\")\n",
    "#reviews per product by rating class, customers seem to review more often when they are happy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 10 most rated titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"product_title\"].value_counts().head(10).plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 titles where the reviews recieved the most votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"product_title\", \"total_votes\"]].nlargest(10, [\"total_votes\"]).plot(x=\"product_title\", y=\"total_votes\", kind=\"barh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 titles have the most 5-star reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"star_rating\"] == 5][\"product_title\"].value_counts().head(10).plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 titles with the lowest rated reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data[\"star_rating\"] == 1][\"product_title\"].value_counts().head(10).plot(kind=\"barh\")\n",
    "#that's where SimCity went, reviewers did not like this game at all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 games with the most helpful reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"product_title\", \"helpful_votes\"]].nlargest(10, [\"helpful_votes\"]).plot(x=\"product_title\", y=\"helpful_votes\", kind=\"barh\")\n",
    "#Customers found reviews of SimCity the most helpful allthough the game also had a lot of bad reviews. this again shows that \n",
    "#this title was highly controversial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we will look at the distribution of vine reviews to non-vine reviews\n",
    "sns.histplot(data, x=\"vine\", stat=\"percent\", multiple=\"dodge\", shrink=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data[data[\"vine\"]==\"Y\"], x=\"star_rating\", stat=\"percent\", multiple=\"dodge\", shrink=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data[data[\"vine\"]==\"N\"], x=\"star_rating\", stat=\"percent\", multiple=\"dodge\", shrink=10)\n",
    "#we can see that the vine reviews are more likely to give 3, 4 or 5 stars compared to the non-vine reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### tokenization and stemming of review_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "stemmer = EnglishStemmer()\n",
    "\n",
    "\n",
    "stop_words.update([\"car\", \"work\", \"product\", \"install\"])\n",
    "\n",
    "def tokenization_and_stemming(text):\n",
    "    tokens = []\n",
    "    # exclude stop words and tokenize the document, generate a list of string \n",
    "    for word in word_tokenize(text):\n",
    "        if word.lower() not in stop_words:\n",
    "            tokens.append(word.lower())\n",
    "\n",
    "    filtered_tokens = []\n",
    "    \n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if token.isalpha(): # filter out non alphabet words like emoji\n",
    "            filtered_tokens.append(token)\n",
    "            \n",
    "    # stemming\n",
    "    # Removes ing also in anything ...\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return_string = \" \".join(stems)\n",
    "    \n",
    "    return return_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review_body = data.dropna(subset=['review_body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review_body[\"processed_reviews\"] = df_review_body[\"review_body\"].apply(lambda x: tokenization_and_stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review_body.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word cloud of processed_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed_reviews = df_review_body.dropna(subset=\"processed_reviews\")\n",
    "processed_review_string = df_processed_reviews.groupby(\"star_rating\").aggregate({\"processed_reviews\":lambda x: \" \\n \".join(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wc_for_rating(rating):\n",
    "    wordcloud = WordCloud(collocations=True).generate(processed_review_string.loc[rating][0][1:5000000].replace(\"one\", \"\").replace(\"use\", \"\").replace(\" br \", \" \").replace(\"car\", \"\").replace(\"work\", \"\"))\n",
    "    # Display the generated image:\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_for_rating(1)\n",
    "wc_for_rating(2)\n",
    "wc_for_rating(3)\n",
    "wc_for_rating(4)\n",
    "wc_for_rating(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP -- end of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
