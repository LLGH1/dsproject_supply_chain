{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f277522c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000,)\n",
      "(200000,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load the Amazon reviews dataset\n",
    "data_en = pd.read_pickle(r\"C:\\Users\\A9236\\Data\\data_en2.pickle\")\n",
    "\n",
    "# Define the input and output data\n",
    "X = data_en[\"lem_pos_ner_rem\"]\n",
    "y = data_en[\"star_rating\"]\n",
    "\n",
    "# Upsample the minority classes to balance the dataset\n",
    "rs = [resample(X[y == sr], y[y == sr], replace=False, n_samples=40000, random_state=123) for sr in [1,2,3,4,5]]\n",
    "X_list = [rs[r][0] for r in range(5)]\n",
    "y_list = [rs[r][1] for r in range(5)]\n",
    "X_us = np.hstack(X_list)\n",
    "y_us = np.hstack(y_list)\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X_us, y_us, test_size= 0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val, random_state=42)\n",
    "\n",
    "print(X_us.shape)\n",
    "print(y_us.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7501e60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "      <th>language</th>\n",
       "      <th>processed_reviews</th>\n",
       "      <th>lem_pos_ner_rem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>12039526</td>\n",
       "      <td>RTIS3L2M1F5SM</td>\n",
       "      <td>B001CXYMFS</td>\n",
       "      <td>737716809</td>\n",
       "      <td>Thrustmaster T-Flight Hotas X Flight Stick</td>\n",
       "      <td>Video Games</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>an amazing joystick. I especially love that yo...</td>\n",
       "      <td>Used this for Elite Dangerous on my mac, an am...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>EN</td>\n",
       "      <td>use elit danger mac amaz joystick especi love ...</td>\n",
       "      <td>use_VERB this_PRON for_ADP on_ADP my_PRON mac_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>9636577</td>\n",
       "      <td>R1ZV7R40OLHKD</td>\n",
       "      <td>B00M920ND6</td>\n",
       "      <td>569686175</td>\n",
       "      <td>Tonsee 6 buttons Wireless Optical Silent Gamin...</td>\n",
       "      <td>Video Games</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Definitely a silent mouse... Not a single clic...</td>\n",
       "      <td>Loved it,  I didn't even realise it was a gami...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>EN</td>\n",
       "      <td>love even realis game mous type silent mous se...</td>\n",
       "      <td>love_VERB it_PRON I_PRON do_AUX not_PART even_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>2331478</td>\n",
       "      <td>R3BH071QLH8QMC</td>\n",
       "      <td>B0029CSOD2</td>\n",
       "      <td>98937668</td>\n",
       "      <td>Hidden Mysteries: Titanic Secrets of the Fatef...</td>\n",
       "      <td>Video Games</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>One Star</td>\n",
       "      <td>poor quality work and not as it is advertised.</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>EN</td>\n",
       "      <td>poor qualiti advertis</td>\n",
       "      <td>poor_ADJ quality_NOUN work_NOUN and_CCONJ not_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>52495923</td>\n",
       "      <td>R127K9NTSXA2YH</td>\n",
       "      <td>B00GOOSV98</td>\n",
       "      <td>23143350</td>\n",
       "      <td>GelTabz Performance Thumb Grips - PlayStation ...</td>\n",
       "      <td>Video Games</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>good, but could be bettee</td>\n",
       "      <td>nice, but tend to slip away from stick in inte...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>EN</td>\n",
       "      <td>nice tend slip away stick intens hard press ga...</td>\n",
       "      <td>nice_ADJ but_CCONJ tend_VERB to_PART slip_VERB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>14533949</td>\n",
       "      <td>R32ZWUXDJPW27Q</td>\n",
       "      <td>B00Y074JOM</td>\n",
       "      <td>821342511</td>\n",
       "      <td>Zero Suit Samus amiibo - Japan Import (Super S...</td>\n",
       "      <td>Video Games</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Great but flawed.</td>\n",
       "      <td>Great amiibo, great for collecting. Quality ma...</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>EN</td>\n",
       "      <td>great amiibo great collect qualiti materi desi...</td>\n",
       "      <td>great_ADJ amiibo_NOUN great_ADJ for_ADP collec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     12039526   RTIS3L2M1F5SM  B001CXYMFS       737716809   \n",
       "1          US      9636577   R1ZV7R40OLHKD  B00M920ND6       569686175   \n",
       "2          US      2331478  R3BH071QLH8QMC  B0029CSOD2        98937668   \n",
       "3          US     52495923  R127K9NTSXA2YH  B00GOOSV98        23143350   \n",
       "4          US     14533949  R32ZWUXDJPW27Q  B00Y074JOM       821342511   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0         Thrustmaster T-Flight Hotas X Flight Stick      Video Games   \n",
       "1  Tonsee 6 buttons Wireless Optical Silent Gamin...      Video Games   \n",
       "2  Hidden Mysteries: Titanic Secrets of the Fatef...      Video Games   \n",
       "3  GelTabz Performance Thumb Grips - PlayStation ...      Video Games   \n",
       "4  Zero Suit Samus amiibo - Japan Import (Super S...      Video Games   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0            5              0            0    N                 Y   \n",
       "1            5              0            0    N                 Y   \n",
       "2            1              0            1    N                 Y   \n",
       "3            3              0            0    N                 Y   \n",
       "4            4              0            0    N                 Y   \n",
       "\n",
       "                                     review_headline  \\\n",
       "0  an amazing joystick. I especially love that yo...   \n",
       "1  Definitely a silent mouse... Not a single clic...   \n",
       "2                                           One Star   \n",
       "3                          good, but could be bettee   \n",
       "4                                  Great but flawed.   \n",
       "\n",
       "                                         review_body review_date language  \\\n",
       "0  Used this for Elite Dangerous on my mac, an am...  2015-08-31       EN   \n",
       "1  Loved it,  I didn't even realise it was a gami...  2015-08-31       EN   \n",
       "2     poor quality work and not as it is advertised.  2015-08-31       EN   \n",
       "3  nice, but tend to slip away from stick in inte...  2015-08-31       EN   \n",
       "4  Great amiibo, great for collecting. Quality ma...  2015-08-31       EN   \n",
       "\n",
       "                                   processed_reviews  \\\n",
       "0  use elit danger mac amaz joystick especi love ...   \n",
       "1  love even realis game mous type silent mous se...   \n",
       "2                              poor qualiti advertis   \n",
       "3  nice tend slip away stick intens hard press ga...   \n",
       "4  great amiibo great collect qualiti materi desi...   \n",
       "\n",
       "                                     lem_pos_ner_rem  \n",
       "0  use_VERB this_PRON for_ADP on_ADP my_PRON mac_...  \n",
       "1  love_VERB it_PRON I_PRON do_AUX not_PART even_...  \n",
       "2  poor_ADJ quality_NOUN work_NOUN and_CCONJ not_...  \n",
       "3  nice_ADJ but_CCONJ tend_VERB to_PART slip_VERB...  \n",
       "4  great_ADJ amiibo_NOUN great_ADJ for_ADP collec...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_en.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0600b3",
   "metadata": {},
   "source": [
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    # Tokenize the text into words\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "    # Convert to lowercase\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "X_train_tok = [preprocess_text(text) for text in X_train]\n",
    "X_val_tok = [preprocess_text(text) for text in X_val]\n",
    "X_test_tok = [preprocess_text(text) for text in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b99166a",
   "metadata": {},
   "source": [
    "### Word2Vec and Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "177663f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train word2vec model\n",
    "w2v_model = Word2Vec(X_train, vector_size=100, window=5, min_count=5, workers=4)\n",
    "#This will create a word2vec model with 100-dimensional vectors, a window size of 5\n",
    "\n",
    "# Create feature vectors\n",
    "def create_features(review_tokens, model):\n",
    "    num_features = model.vector_size\n",
    "    features = np.zeros((len(review_tokens), num_features), dtype=\"float32\")\n",
    "    for i, tokens in enumerate(review_tokens):\n",
    "        for token in tokens:\n",
    "            if token in model.wv.key_to_index:\n",
    "                features[i] += model.wv.get_vector(token)\n",
    "    return features\n",
    "\n",
    "X_train_features = create_features(X_train, w2v_model)\n",
    "X_test_features = create_features(X_test, w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07387a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.49      0.41      3945\n",
      "           2       0.30      0.29      0.29      4006\n",
      "           3       0.27      0.22      0.24      3925\n",
      "           4       0.28      0.23      0.25      4000\n",
      "           5       0.43      0.44      0.44      4124\n",
      "\n",
      "    accuracy                           0.33     20000\n",
      "   macro avg       0.33      0.33      0.33     20000\n",
      "weighted avg       0.33      0.33      0.33     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train random forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_features, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred = rf_model.predict(X_test_features)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5398944",
   "metadata": {},
   "source": [
    "### Decision Tree Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f54e2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "900 fits failed out of a total of 2000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 864, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 782, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.486325          nan 0.48621667 0.49353333\n",
      " 0.49445    0.47959167 0.49243333 0.48621667        nan        nan\n",
      "        nan        nan        nan 0.4935     0.49500833        nan\n",
      " 0.49255    0.48621667        nan        nan 0.48640833        nan\n",
      " 0.49139167 0.49353333 0.49318333 0.4851     0.4959     0.49119167\n",
      "        nan        nan        nan        nan        nan 0.4935\n",
      " 0.49303333        nan 0.495875   0.49143333        nan        nan\n",
      " 0.48638333        nan 0.49131667 0.49353333 0.49328333 0.4863\n",
      " 0.496075   0.491525          nan        nan        nan        nan\n",
      "        nan 0.4935     0.49345           nan 0.49586667 0.49133333\n",
      "        nan        nan 0.48633333        nan 0.49128333 0.49353333\n",
      " 0.49344167 0.4863     0.49603333 0.4914            nan        nan\n",
      "        nan        nan        nan 0.4935     0.493425          nan\n",
      " 0.496025   0.4912            nan        nan 0.48614167        nan\n",
      " 0.4863     0.49341667 0.49494167 0.47885    0.492525   0.486225\n",
      "        nan        nan        nan        nan        nan 0.4935\n",
      " 0.49500833        nan 0.492575   0.486175          nan        nan\n",
      " 0.48615           nan 0.49130833 0.49341667 0.49346667 0.48378333\n",
      " 0.495775   0.491325          nan        nan        nan        nan\n",
      "        nan 0.4935     0.49303333        nan 0.49594167 0.49134167\n",
      "        nan        nan 0.48615           nan 0.49140833 0.49341667\n",
      " 0.4935     0.48613333 0.49603333 0.49135833        nan        nan\n",
      "        nan        nan        nan 0.4935     0.49345           nan\n",
      " 0.49586667 0.49148333        nan        nan 0.48621667        nan\n",
      " 0.49146667 0.49341667 0.49351667 0.48613333 0.49571667 0.49145\n",
      "        nan        nan        nan        nan        nan 0.4935\n",
      " 0.493425          nan 0.49593333 0.49131667        nan        nan\n",
      " 0.48611667        nan 0.4862     0.49355833 0.49475    0.47873333\n",
      " 0.49253333 0.48623333        nan        nan        nan        nan\n",
      "        nan 0.4935     0.49500833        nan 0.49248333 0.4862\n",
      "        nan        nan 0.486175          nan 0.49133333 0.49355833\n",
      " 0.49340833 0.48404167 0.4959     0.4914            nan        nan\n",
      "        nan        nan        nan 0.4935     0.49303333        nan\n",
      " 0.49598333 0.49126667        nan        nan 0.48618333        nan\n",
      " 0.49139167 0.49355833 0.49345833 0.48619167 0.49599167 0.49131667\n",
      "        nan        nan        nan        nan        nan 0.4935\n",
      " 0.49345           nan 0.49600833 0.4914            nan        nan\n",
      " 0.48616667        nan 0.49136667 0.49355833 0.4935     0.48619167\n",
      " 0.49588333 0.49140833        nan        nan        nan        nan\n",
      "        nan 0.4935     0.493425          nan 0.49595833 0.491225\n",
      "        nan        nan 0.4862            nan 0.48616667 0.49355\n",
      " 0.49426667 0.481425   0.4924     0.48619167        nan        nan\n",
      "        nan        nan        nan 0.4935     0.49500833        nan\n",
      " 0.4925     0.48621667        nan        nan 0.48620833        nan\n",
      " 0.49125833 0.49355    0.49331667 0.48365833 0.495975   0.49136667\n",
      "        nan        nan        nan        nan        nan 0.4935\n",
      " 0.49303333        nan 0.49598333 0.491325          nan        nan\n",
      " 0.48616667        nan 0.491375   0.49355    0.4935     0.48611667\n",
      " 0.49605    0.4914            nan        nan        nan        nan\n",
      "        nan 0.4935     0.49345           nan 0.49611667 0.49135\n",
      "        nan        nan 0.48621667        nan 0.49146667 0.49355\n",
      " 0.4935     0.48611667 0.49600833 0.49130833        nan        nan\n",
      "        nan        nan        nan 0.4935     0.493425          nan\n",
      " 0.49600833 0.49138333        nan        nan 0.48615           nan\n",
      " 0.486225   0.49350833 0.49476667 0.48325    0.492425   0.48623333\n",
      "        nan        nan        nan        nan        nan 0.4935\n",
      " 0.49500833        nan 0.49258333 0.48625833        nan        nan\n",
      " 0.4862            nan 0.49146667 0.49350833 0.49375833 0.484375\n",
      " 0.49579167 0.49131667        nan        nan        nan        nan\n",
      "        nan 0.4935     0.49303333        nan 0.49595833 0.49125833\n",
      "        nan        nan 0.4862            nan 0.4913     0.49350833\n",
      " 0.49355    0.48616667 0.49590833 0.49138333        nan        nan\n",
      "        nan        nan        nan 0.4935     0.49345           nan\n",
      " 0.4961     0.49131667        nan        nan 0.48626667        nan\n",
      " 0.49143333 0.49350833 0.49353333 0.48616667 0.49605    0.49133333\n",
      "        nan        nan        nan        nan        nan 0.4935\n",
      " 0.493425          nan 0.49615    0.49130833]\n",
      "  warnings.warn(\n",
      "C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 100, 'max_iter': 5000, 'penalty': 'none', 'solver': 'sag'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\A9236\\AppData\\Local\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=100, max_iter=5000, penalty=&#x27;none&#x27;, solver=&#x27;sag&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=100, max_iter=5000, penalty=&#x27;none&#x27;, solver=&#x27;sag&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=100, max_iter=5000, penalty='none', solver='sag')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10, 20, 30],\n",
    "    'min_samples_leaf': [1, 2, 4, 8, 16],\n",
    "}\n",
    "\n",
    "# Create a decision tree classifier object\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search_dt = GridSearchCV(dt_model, param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search_dt.fit(X_train_features, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print('Best hyperparameters:', grid_search_dt.best_params_)\n",
    "\n",
    "# Use the best hyperparameters to create the final model\n",
    "dt_model_final = DecisionTreeClassifier(**grid_search_dt.best_params_)\n",
    "dt_model_final.fit(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1b16619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.74      0.66      3945\n",
      "           2       0.45      0.35      0.40      4006\n",
      "           3       0.42      0.30      0.35      3925\n",
      "           4       0.42      0.40      0.41      4000\n",
      "           5       0.56      0.73      0.63      4124\n",
      "\n",
      "    accuracy                           0.51     20000\n",
      "   macro avg       0.49      0.50      0.49     20000\n",
      "weighted avg       0.49      0.51      0.49     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test set\n",
    "y_pred = dt_model_final.predict(X_test_features)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b84dbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save logistic regression model\n",
    "import pickle\n",
    "with open('logistic_regression_model.pkl', 'wb') as file:\n",
    "    pickle.dump(lr_model_final, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6f9aa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_en.to_csv(\"path\", compression='zip')\n",
    "#use stopwords from Sebastian\n",
    "#interpret results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
